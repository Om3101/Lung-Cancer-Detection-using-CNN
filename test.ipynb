{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\HP\\.cache\\kagglehub\\datasets\\adityamahimkar\\iqothnccd-lung-cancer-dataset\\versions\\2\n",
      "Contents of the directory: ['Test cases', 'The IQ-OTHNCCD lung cancer dataset']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"adityamahimkar/iqothnccd-lung-cancer-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# List the contents of the downloaded directory\n",
    "print(\"Contents of the directory:\", os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of 'The IQ-OTHNCCD lung cancer dataset': ['The IQ-OTHNCCD lung cancer dataset']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATASET_PATH = \"C:\\\\Users\\\\HP\\\\.cache\\\\kagglehub\\\\datasets\\\\adityamahimkar\\\\iqothnccd-lung-cancer-dataset\\\\versions\\\\2\"\n",
    "subfolders = os.listdir(os.path.join(DATASET_PATH, \"The IQ-OTHNCCD lung cancer dataset\"))\n",
    "\n",
    "print(\"Contents of 'The IQ-OTHNCCD lung cancer dataset':\", subfolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset folder contents: ['Bengin cases', 'IQ-OTH_NCCD lung cancer dataset.txt', 'Malignant cases', 'Normal cases']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define base dataset path\n",
    "BASE_PATH = \"C:\\\\Users\\\\HP\\\\.cache\\\\kagglehub\\\\datasets\\\\adityamahimkar\\\\iqothnccd-lung-cancer-dataset\\\\versions\\\\2\"\n",
    "NESTED_PATH = os.path.join(BASE_PATH, \"The IQ-OTHNCCD lung cancer dataset\", \"The IQ-OTHNCCD lung cancer dataset\")\n",
    "\n",
    "# List contents of the nested folder\n",
    "print(\"Final dataset folder contents:\", os.listdir(NESTED_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Bengin cases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:01<00:00, 74.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Malignant cases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 561/561 [00:07<00:00, 70.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Normal cases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416/416 [00:05<00:00, 73.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete! Data saved in cleaned_dataset/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Dataset Paths\n",
    "RAW_DATASET_PATH = \"C:\\\\Users\\\\HP\\\\.cache\\\\kagglehub\\\\datasets\\\\adityamahimkar\\\\iqothnccd-lung-cancer-dataset\\\\versions\\\\2\\\\The IQ-OTHNCCD lung cancer dataset\\\\The IQ-OTHNCCD lung cancer dataset\"\n",
    "CLEANED_DATASET_PATH = \"cleaned_dataset\"\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Class categories\n",
    "CATEGORIES = [\"Bengin cases\", \"Malignant cases\", \"Normal cases\"]\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(CLEANED_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "def process_and_save_images():\n",
    "    data, labels = [], []\n",
    "    for label, category in enumerate(CATEGORIES):\n",
    "        input_folder = os.path.join(RAW_DATASET_PATH, category)\n",
    "        output_folder = os.path.join(CLEANED_DATASET_PATH, category)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        print(f\"Processing {category}...\")\n",
    "\n",
    "        for img_name in tqdm(os.listdir(input_folder)):\n",
    "            img_path = os.path.join(input_folder, img_name)\n",
    "\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                output_img_path = os.path.join(output_folder, os.path.splitext(img_name)[0] + \".jpg\")\n",
    "                cv2.imwrite(output_img_path, img)\n",
    "\n",
    "                img = img.astype(\"float32\") / 255.0\n",
    "                data.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_name}: {e}\")\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Process images\n",
    "data, labels = process_and_save_images()\n",
    "\n",
    "# Ensure images were processed\n",
    "if len(data) == 0:\n",
    "    raise RuntimeError(\"No images processed! Check dataset path.\")\n",
    "\n",
    "# Split dataset (80% train, 10% validation, 10% test)\n",
    "x_temp, x_test, y_temp, y_test = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_temp, y_temp, test_size=0.125, stratify=y_temp, random_state=42)\n",
    "\n",
    "# SMOTE resampling for balancing dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train.reshape(-1, IMG_SIZE * IMG_SIZE * 3), y_train)\n",
    "x_train_resampled = x_train_resampled.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_resampled = to_categorical(y_train_resampled, num_classes=3)\n",
    "y_valid = to_categorical(y_valid, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "# Save preprocessed data\n",
    "np.save(\"x_train.npy\", x_train_resampled)\n",
    "np.save(\"y_train.npy\", y_train_resampled)\n",
    "np.save(\"x_valid.npy\", x_valid)\n",
    "np.save(\"y_valid.npy\", y_valid)\n",
    "np.save(\"x_test.npy\", x_test)\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "\n",
    "print(\"Preprocessing complete! Data saved in cleaned_dataset/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.95      0.79      0.86        24\n",
      "   Malignant       1.00      1.00      1.00       113\n",
      "      Normal       0.94      0.99      0.96        83\n",
      "\n",
      "    accuracy                           0.97       220\n",
      "   macro avg       0.96      0.93      0.94       220\n",
      "weighted avg       0.97      0.97      0.97       220\n",
      "\n",
      "[[ 19   0   5]\n",
      " [  0 113   0]\n",
      " [  1   0  82]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"C:\\\\Users\\\\HP\\\\Desktop\\\\Workspace\\\\lung_cancer_densenet169.h5\")\n",
    "\n",
    "# Predict test data\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Benign\", \"Malignant\", \"Normal\"]))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9613 - loss: 0.1060\n",
      "Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9854 - loss: 0.0820\n",
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss, test_acc = model.evaluate(x_valid, y_valid)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
